# -*- coding: utf-8 -*-
"""Finatics_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gnRWQAY2Evkrzk7ADhQ7aLzoIzOHcEUg

# **SETUP**

## Import libraries and packages
"""

# %%
import numpy as np
from collections import deque
import copy
from tqdm import tqdm
import seaborn as sns
sns.set_theme(style="ticks")
import statsmodels.api as sm
import matplotlib.ticker as mtick
import pandas as pd
import matplotlib.pyplot as plt

"""## Class AMM"""

# %%
class amm():

    def __init__(self, Rx, Ry, phi):
        """
        instantiate the class

        Parameters
        ----------
        Rx : array (K,)
            initial reservese of token-X in each pool
        Ry : array (K,)
            initial reservese of token-Y in each pool
        phi : array (K,)
            the pool fee

        Returns
        -------
        None.

        """

        assert (len(Rx) == len(Ry)) & (len(Ry)==len(phi)), "length of Rx, Ry, and phi must be the same."

        self.Rx = 1*Rx
        self.Ry = 1*Ry
        self.phi = 1*phi
        self.N = len(self.Rx)

        # number of LP tokens for each pool
        self.L = np.sqrt(self.Rx*self.Ry)

        # the trader begins with no LP tokens
        self.l = np.zeros(len(self.L))


    def swap_x_to_y(self, x, quote=False):
        """
        swap token-X for token-Y across all pools simulataneously

        Parameters
        ----------
        x : array (K,)
            the amount of token-X to swap in each AMM pool.
        quote: bool, optional
            deafult is False.
            If False, then pool states are updated.
            If True, pool states are not updated.

        Returns
        -------
        y : array (K,)
            the amount of token-Y you receive from each pool.

        """

        # Calculate amount of token-Y receivable
        y = x * (1 - self.phi) * self.Ry / (self.Rx + (1 - self.phi) * x)

        # Check if there's enough token-Y in reserves to trade
        if np.any(self.Ry < y):
            raise ValueError("Not enough Y-coins in Reserve")

        # Update reserves
        if not quote:
            self.Rx += x
            self.Ry -= y
            # self.L = np.sqrt(self.Rx*self.Ry)

        return y


    def swap_y_to_x(self, y, quote=False):
        """
        swap token-Y for token-X across all pools simulataneously

        Parameters
        ----------
        y : array (K,)
            the amount of token-Y to swap in each AMM pool.
        quote: bool, optional
            deafult is False.
            If False, then pool states are updated.
            If True, pool states are not updated.

        Returns
        -------
        x : array (K,)
            the amount of token-X you receive from each pool.

        """

        # Calculate amount of token-X receivable
        x = y * (1 - self.phi) * self.Rx / (self.Ry + (1 - self.phi) * y)

        # Check if there's enough token-Y in reserves to trade
        if np.any(self.Rx < x):
            raise ValueError("Not enough X-coins in Reserve")

        # Update reserves
        if not quote:
            self.Ry += y
            self.Rx -= x
            # self.L = np.sqrt(self.Rx*self.Ry)

        return x


    def mint(self, x, y):
        """
        mint LP tokens across all pools

        Parameters
        ----------
        x : array (K,)
            amount of token-X submitted to each pool.
        y : array (K,)
            amount of token-Y submitted to each pool.

        Returns
        -------
        l : array (K,)
            The amount of LP tokens you receive from each pool.

        """

        for k in range(len(self.Rx)):
            assert np.abs(((x[k]/y[k])-self.Rx[k]/self.Ry[k])) < 1e-5, "pool " + str(k) + " has incorrect submission of tokens"

        # If minting condition (5) is satisfied, update trader's LP coins
        x = np.array(x)
        y = np.array(y)
        l_add = x / self.Rx * self.L
        # Update reserves & total LP coins
        self.Rx += x
        self.Ry += y
        self.l += l_add
        self.L += l_add

        return l_add


    def burn(self, l_withdraw):
        """
        burn LP tokens across all pools

        Parameters
        ----------
        l : array (K,)
            amount of LP tokens to burn

        Returns
        -------
        x : array (K,)
            The amount of token-X received across
        y : array (K,)
            The amount of token-Y received across

        """
        x = np.zeros(len(self.L))
        y = np.zeros(len(self.L))
        for k in range(len(self.L)):
            assert l_withdraw[k] <= self.l[k], "you have insufficient LP tokens"

        # Calculate coins received
        x = l_withdraw / self.L * self.Rx
        y = l_withdraw / self.L * self.Ry

        # Update Reserves, total & trader's LP coins
        self.Rx -= x
        self.Ry -= y
        self.L -= l_withdraw
        self.l -= l_withdraw

        return copy.deepcopy([x, y])


    def swap_and_mint(self, x):
        """
        a method that determines the correct amount of y for each x within the corresponding pool
        to swap and then mint tokens with the reamaing x and the y you received

        Parameters
        ----------
        x : array (K,)
            amount of token-X you have for each pool.

        Returns
        -------
        l : array (K,)
            The amount of LP tokens you receive from each pool.

        """
        # Convert x from list to array
        x = np.array(x)

        # Calculate the proportion of x not swapped
        theta = 1 + (2 - self.phi) * self.Rx / (2 * (1 - self.phi) * x) *\
                (1 - np.sqrt(1 + 4 * x * (1 - self.phi) / self.Rx / (2 - self.phi) ** 2))

        # Swap (1 - theta) coins-X for coins-Y
        y = self.swap_x_to_y(x * (1 - theta), quote=False)

        # Mint
        l = self.mint(x * theta, y)

        return l


    def burn_and_swap(self, l):
        """
        a method that burns your LP tokens, then swaps y to x and returns only x

        Parameters
        ----------
        l : array (K,)
            amount of LP tokens you have for each pool.

        Returns
        -------
        x : array (K,)
            The amount of token-x you receive at the end.

        """
        # Burn liquidity coins
        x, y = self.burn(l)
        total_y = np.sum(y)

        pools = []
        x_max = -1
        pool_max = -1
        for pool in range(len(self.L)):
            y_trade = np.zeros(len(self.L))
            y_trade[pool] = total_y
            x_receivable = -1
            try:
              x_receivable = np.sum(self.swap_y_to_x(y_trade, quote = True))
            except ValueError:
              pass

            if x_receivable > 0 and x_receivable > x_max:
              pool_max = pool
              x_max = x_receivable


        y_trade = np.zeros(len(self.L))
        try:
          y_trade[pool_max] = total_y
        except IndexError:
          raise IndexError("Total X cannot be withdrawn from a single pool")
        x_receivable = np.sum(self.swap_y_to_x(y_trade, quote = False))
        return x_receivable + np.sum(x)



    def simulate(self, kappa, p, sigma, T=1, batch_size=256, show_bars = True):
        """
        Simulate trajectories of all AMM pools simultanesouly.

        Parameters
        ----------
        kappa : array (K+1,)
            rate of arrival of swap events X->Y and Y->X.
            kappa[0,:] is for a common event across all pools
        p : array (K+1,2)
            probability of swap X to Y event conditional on an event arriving.
            p[0,:] is for a common event across all pools
        sigma : array (K+1,2)
            standard deviation of log volume of swap events.
            sigma[0,:] is for a common event across all pools
        T : float, optional: default is 1.
            The amount of (calendar) time to simulate over
        batch_size : int, optional, default is 256.
            the number of paths to generate.

        Returns
        -------
        pools : deque, len=batch_size
            Each element of the list is the pool state at the end of the simulation for that scenario
        Rx_t : deque, len= batch_size
            Each element of the list contains a sequence of arrays.
            Each array shows the reserves in token-X for all AMM pools after each transaction.
        Ry_t : deque, len=batch_size
            Each element of the list contains a sequence of arrays.
            Each array shows the reserves in token-Y for all AMM pools after each transaction.
        v_t : deque, len=batch_size
            Each element of the list contains a sequence of arrays.
            Each array shows the volumes of the transaction sent to the various AMM pools -- the transaction is
            either a swap X for Y or swap Y for X for a single pool, or across all pools at once
        event_type_t : deque, len=batch_size
            Each element of the list contains a sequence of arrays.
            Each array shows the event type. event_type=0 if it is a swap sent to all pools simultaneously,
            otherwise, the swap was sent to pool event_type
        event_direction_t : deque, len=batch_size
            Each element of the list contains a sequence of arrays.
            Each array shows the directi of the swap.
            event_direction=0 if swap X -> Y
            event_direction=1 if swap Y -> X

        """

        # used for generating Poisson random variables for all events
        sum_kappa = np.sum(kappa)

        # used for thinning the Poisson process
        pi = kappa/sum_kappa

        # store the list of reservese generated by the simulation
        def make_list(batch_size):
          x = deque(maxlen=batch_size)
          x = [None] * batch_size
          return x

        Rx_t = make_list(batch_size)
        Ry_t = make_list(batch_size)
        v_t = make_list(batch_size)
        event_type_t = make_list(batch_size)
        event_direction_t = make_list(batch_size)
        pools = make_list(batch_size)

        if show_bars:
          for k in tqdm(range(batch_size)):

              N = np.random.poisson(lam = sum_kappa*T)

              Rx = np.zeros((N,len(self.Rx)))
              Ry = np.zeros((N,len(self.Rx)))
              v = np.zeros((N,len(self.Rx)))
              event_type = np.zeros(N, int)
              event_direction = np.zeros(N, int)

              pools[k] = copy.deepcopy(self)

              for j in range(N):

                  # generate the type of event associated with each event
                  event_type[j] = np.random.choice(len(kappa), p=pi)

                  # the direction of the swap 0 = x-> y, 1 = y -> x
                  event_direction[j] = int(np.random.rand()< p[event_type[j]])

                  if event_direction[j] == 0:
                      mu = np.zeros(len(pools[k].Rx)) # deposit X and get Y
                  else:
                      mu = np.log(pools[k].Ry/pools[k].Rx) # deposit Y and get X

                  if event_type[j] == 0:
                      # there is a swap across all venues
                      v[j,:] = np.exp((mu-0.5*sigma[0]**2) + sigma[0]*np.random.randn() )

                  else:

                      # there is a swap only on a specific venue
                      v[j,:] = np.zeros(len(pools[k].Rx))
                      mu = mu[event_type[j]-1]
                      v[j,event_type[j]-1] = np.exp((mu-0.5*sigma[event_type[j]]**2) \
                                                    + sigma[event_type[j]]*np.random.randn() )

                  if event_direction[j] == 0:
                      pools[k].swap_x_to_y(v[j,:]) # submit X and get Y
                  else:
                      pools[k].swap_y_to_x(v[j,:]) # submit Y and get X

                  Rx[j,:] = 1*pools[k].Rx
                  Ry[j,:] = 1*pools[k].Ry

              Rx_t[k] = Rx
              Ry_t[k] = Ry
              v_t[k] = v
              event_type_t[k] = event_type
              event_direction_t[k] = event_direction
        else:
          for k in range(batch_size):

              N = np.random.poisson(lam = sum_kappa*T)

              Rx = np.zeros((N,len(self.Rx)))
              Ry = np.zeros((N,len(self.Rx)))
              v = np.zeros((N,len(self.Rx)))
              event_type = np.zeros(N, int)
              event_direction = np.zeros(N, int)

              pools[k] = copy.deepcopy(self)

              for j in range(N):

                  # generate the type of event associated with each event
                  event_type[j] = np.random.choice(len(kappa), p=pi)

                  # the direction of the swap 0 = x-> y, 1 = y -> x
                  event_direction[j] = int(np.random.rand()< p[event_type[j]])

                  if event_direction[j] == 0:
                      mu = np.zeros(len(pools[k].Rx)) # deposit X and get Y
                  else:
                      mu = np.log(pools[k].Ry/pools[k].Rx) # deposit Y and get X

                  if event_type[j] == 0:
                      # there is a swap across all venues
                      v[j,:] = np.exp((mu-0.5*sigma[0]**2) + sigma[0]*np.random.randn() )

                  else:

                      # there is a swap only on a specific venue
                      v[j,:] = np.zeros(len(pools[k].Rx))
                      mu = mu[event_type[j]-1]
                      v[j,event_type[j]-1] = np.exp((mu-0.5*sigma[event_type[j]]**2) \
                                                    + sigma[event_type[j]]*np.random.randn() )

                  if event_direction[j] == 0:
                      pools[k].swap_x_to_y(v[j,:]) # submit X and get Y
                  else:
                      pools[k].swap_y_to_x(v[j,:]) # submit Y and get X

                  Rx[j,:] = 1*pools[k].Rx
                  Ry[j,:] = 1*pools[k].Ry

              Rx_t[k] = Rx
              Ry_t[k] = Ry
              v_t[k] = v
              event_type_t[k] = event_type
              event_direction_t[k] = event_direction

        return pools, Rx_t, Ry_t, v_t, event_type_t, event_direction_t

    def feed_forward(self, v_t, event_direction_t):
      """
      Function that replicates simulate() but uses pre-stored v_t and event_direction_t
      (ignoring the effect of theta on v_t)
      """

      def make_list(batch_size):
        x = deque(maxlen=batch_size)
        x = [None] * batch_size
        return x

      Rx_t = make_list(len(v_t))
      Ry_t = make_list(len(v_t))
      pools = make_list(len(v_t))

      for k in tqdm(range(batch_size)):
          v = v_t[k]
          event_direction = event_direction_t[k]
          N = len(event_direction)
          Rx = np.zeros((N,len(self.Rx)))
          Ry = np.zeros((N,len(self.Rx)))


          pools[k] = copy.deepcopy(self)

          for j in range(N):

              if event_direction[j] == 0:
                  pools[k].swap_x_to_y(v[j,:]) # submit X and get Y
              else:
                  pools[k].swap_y_to_x(v[j,:]) # submit Y and get X

              Rx[j,:] = 1*pools[k].Rx
              Ry[j,:] = 1*pools[k].Ry

          Rx_t[k] = Rx
          Ry_t[k] = Ry
      return pools, Rx_t, Ry_t

"""## ================================================================================================================================================================

# **TESTING - TRADING FUNCTIONS**

---
"""

################################################### TESTING ###############################################################################
np.set_printoptions(formatter={'float': lambda x: "{0:0.2f}".format(x)})

# %%
""" Initialize List of Pools """
print("POOLS INITIALIZATION")
print ("-------------------------Code-----------------------")
Rx0 = np.array([100 , 100 , 100 ], float)
Ry0 = np.array([1000 , 1000 , 1000 ], float)
phi = np.array([0.003 , 0.003 , 0.003 ], float)
pools = amm(Rx=Rx0 , Ry=Ry0 , phi=phi)
print ("Available LP coins :", pools.L)

print ("-------------------------Actual-----------------------")
print("Available LP coins : [316.228 316.228 316.228]\n\n")



# %%
""" Swaping X for Y """
print("SWAPING X FOR Y")
print ("-------------------------Code-----------------------")
y = pools.swap_x_to_y ([1 , 0.5 , 0.1], quote = False)
print ("Obtained Y coins :", y )
print ("Reserves in X :", pools . Rx )
print ("Reserves in Y :", pools . Ry )

print ("-------------------------Actual-----------------------")
print("Obtained Y coins : [9.87 4.96 1.]\nReserves in X : [101. 100.5 100.1]\nReserves in Y : [990.13 995.04 999.]\n\n")




# %%
""" Minting """
print("MINTING")
print ("-------------------------Code-----------------------")
x = [1 , 1 , 1]
y = x * pools.Ry / pools.Rx
l = pools . mint ( x = x , y = y )
print ('Trader LP coins : ', pools . l)
print ('Pool LP coins : ', pools . L )

print ("-------------------------Actual-----------------------")
print("Trader LP coins : [3.13 3.15 3.16]\nPool LP coins : [319.36 319.37 319.39]\n\n")



# %%
""" Burning """
print("BURNING")
print ("-------------------------Code-----------------------")
x , y = pools.burn(l)
print ('Trader LP coins :', pools.l )
print ('Trader X coins :', x )
print ('Trader Y coins :', y )
print ('Pool LP coins :', pools.L)
# print ('RX coins: ', pools.Rx)
# print ('RY coins: ', pools.Ry)

print ("-------------------------Actual-----------------------")
print("Trader LP coins : [0.00 0.00 0.00]\nTrader X coins : [1. 1. 1.]\nTrader Y coins : [9.8 9.9 9.98]\nPool LP coins : [316.23 316.23 316.23]\n\n")



# %%
""" Swap and Mint"""
print("SWAP AND MINT")
print ("-------------------------Code-----------------------")
l = pools.swap_and_mint ([10 , 10 , 10])
print ('Minted LP coins :', l )
print ('Total trader LP coins :', pools. l )
print ('Available LP coins :', pools. L )
# print ('RX coins: ', pools.Rx)
# print ('RY coins: ', pools.Ry)

print ("-------------------------Actual-----------------------")
print("Minted LP coins : [15.26 15.34 15.40]\nTotal trader LP coins : [15.26 15.34 15.40]\nAvailable LP coins : [331.49 331.56 331.62]\n\n")



# %%
""" Burn and Swap """
print("BURN AND SWAP")
print ("-------------------------Code-----------------------")
total_x = pools. burn_and_swap ( l )
print (f'Number of X coins received : {total_x:.2f}' )
print ('Total trader liquidity coins :', pools. l )
print ('Available liquidity coins :', pools. L )

print ("-------------------------Actual-----------------------")
print("Number of X coins received : 28.80\nTotal trader liquidity coins : [0.00 0.00 0.00]\nAvailable liquidity coins : [316.23 316.23 316.23]\n\n")

"""## ================================================================================================================================================================

# **TESTING - TRADING SIMULATION**

#### Entire Investment Process
"""

np.set_printoptions(formatter={'float': lambda x: "{0:0.3f}".format(x)})

""" Fix the seed """
np.random.seed(999983)

""" Initialise the pools """
Rx0   = np.array([100,   100,   100], float)
Ry0   = np.array([1000,  1000,  1000], float)
phi   = np.array([0.003, 0.003, 0.003], float)

pools = amm(Rx=Rx0, Ry=Ry0, phi=phi)

""" Swap and mint """
xs_0 = [10, 10, 10]
l    = pools.swap_and_mint(xs_0)

""" Simulate 1000 paths of trading in the pools """
batch_size = 1_000
T          = 60
kappa      = np.array([0.6,  0.5,  1,     2])
p          = np.array([0.85, 0.3,  0.2,   0.3])
sigma      = np.array([0.05, 0.01, 0.025, 0.05])

end_pools, Rx_t, Ry_t, v_t, event_type_t, event_direction_t =\
        pools.simulate( kappa = kappa, p = p, sigma = sigma, T = T, batch_size = batch_size)

print('\n')
print("-------------------------Code-----------------------")
print('Reserves in coin X for scenario 0:', end_pools[0].Rx)
print('Reserves in coin Y for scenario 0:', end_pools[0].Ry)

print("-------------------------Actual-----------------------")
print("Reserves in coin X for scenario 0: [96.491 118.366 121.083]")
print("Reserves in coin Y for scenario 0: [1142.267 931.521 912.311]\n")

"""#### Mean and StdDev of Return

"""

""" Burn and swap all coins into x """
x_T = np.zeros(batch_size)
for k in range(batch_size):
  x_T[k] = np.sum(end_pools [k]. burn_and_swap(l))
x_0 = np.sum(xs_0)
log_ret = np.log(x_T) - np.log(x_0)

mean_ret = np.mean(log_ret)/T*100
std_ret = np.std(log_ret)/np.sqrt(T)*100

print("-------------------------Code-----------------------")
print (f'Average performance: {(np.mean(log_ret)/T*100):.4f}')
print (f'Std. Dev. of performance: {(np.std(log_ret)/np.sqrt(T)*100):.4f}')

print("-------------------------Actual-----------------------")
print("Average performance: 0.2629")
print("Std. Dev. of performance: 1.1604")

"""#### VaR and CVaR of Return"""

fig, ax = plt.subplots(1, 1, sharex=True, figsize=(5,4), sharey=True)

x_0      = np.sum(xs_0)
log_ret  = np.log(x_T) - np.log(x_0)

# histogram plot
sns.histplot(ax=ax, x=100*log_ret, kde=True)
ax.set_xlabel(r'$Return$')

# compute cvar
alpha = 0.95 # 95%
qtl   = np.quantile(-log_ret, alpha)
cvar  = np.mean(-log_ret[-log_ret>=qtl])

zeta  = 0.05 # 5%
ax.axvline(zeta*100, linestyle='--', color='lime', label=r"$\zeta = 5\%$")
ax.axvline(-qtl*100, linestyle='--', color='blue', label=r"$- VaR_\alpha\approx$"+f'${-round(100*qtl, 2)}\%$')
ax.axvline(-cvar*100, linestyle='--', color='red', label=r'$- CVaR_\alpha\approx$'+f'${-round(100*cvar, 2)}\%$')

ax.xaxis.set_major_formatter(mtick.PercentFormatter())

plt.legend(handlelength=0.8, framealpha=0.4, loc='upper left')
plt.tight_layout()
plt.savefig('cvar.pdf')
plt.show()

"""## ================================================================================================================================================================

# DEFAULT PARAMS AND HELPFUL FUNCTIONS

#### Fixed Parameters
"""

N_pools = 6

params={'N_pools' : N_pools,
        'Rx0' : 100*np.ones(N_pools),
        'Ry0' : 1000*np.ones(N_pools),
        'phi' :  0.03*np.ones(N_pools),
        'x_0' : 10,
        'alpha' : 0.9,
        'q' : 0.8,
        'zeta' : 0.05,
        'batch_size' : 1_000,
        'kappa' : [0.25, 0.5,  0.5,  0.45,  0.45,  0.4,  0.3  ],
        'sigma' :  [1, 0.3, 0.5, 1, 1.25, 2, 4],
        'p' : [0.45, 0.45, 0.4, 0.38, 0.36, 0.34, 0.3],
        'T' : 60,
        'seed' : 4294967143}

"""#### Functions for Testing New Strats"""

df_metrics = pd.DataFrame(columns=['Strategy','Prob','Mean', 'STD', 'VaR', 'CVaR'])


def strat_test(theta, df_metrics, strat_name = None, print_graph = False):

  np.set_printoptions(formatter={'float': lambda x: "{0:0.6f}".format(x)})

  """ Fix the seed """
  np.random.seed(params["seed"])

  """ Initialise the pools """
  Rx0 = params["Rx0"]
  Ry0 = params["Ry0"]
  phi = params["phi"]
  pools = amm( Rx=Rx0 , Ry=Ry0 , phi=phi)
  xs_0 = theta*params['x_0']

  """ Swap and mint """
  l = pools.swap_and_mint(xs_0)

  """ Simulate 100 paths of trading in the pools """
  batch_size = params["batch_size"]
  T = params["T"]
  kappa = params["kappa"]
  p = params["p"]
  sigma = params["sigma"]

  end_pools, Rx_t, Ry_t, v_t, event_type_t, event_direction_t =\
  pools.simulate( kappa = kappa , p = p , sigma = sigma , T = T , batch_size = batch_size)

  """ Burn and swap all coins into x """
  x_T = np.zeros(batch_size)
  for k in range(batch_size):
    x_T[k] = np.sum(end_pools[k].burn_and_swap(l))
  x_0 = np.sum(xs_0)
  log_ret = np.log(x_T) - np.log(x_0)

  # compute condition probability
  zeta  = params["zeta"] # 5%
  prob = np.mean(log_ret >= zeta)

  # Compute mean and standard deviation of log returns
  mean_ret = np.mean(log_ret) / T * 100
  std_ret = np.std(log_ret) / np.sqrt(T) * 100

  # compute cvar
  alpha = params["alpha"]
  qtl   = np.quantile(-log_ret, alpha)
  cvar  = np.mean(-log_ret[-log_ret>=qtl])

  # histogram plot
  if print_graph:
    fig, ax = plt.subplots(1, 1, sharex=True, figsize=(5,4), sharey=True)
    sns.histplot(ax=ax, x=100*log_ret, kde=True)
    ax.set_xlabel(r'$Return$')

    ax.axvline(zeta*100, linestyle='--', color='lime', label=r"$\zeta = 5\%$")
    ax.axvline(-qtl*100, linestyle='--', color='blue', label=r"$- VaR_\alpha\approx$"+f'${-round(100*qtl, 2)}\%$')
    ax.axvline(-cvar*100, linestyle='--', color='red', label=r'$- CVaR_\alpha\approx$'+f'${-round(100*cvar, 2)}\%$')

    ax.xaxis.set_major_formatter(mtick.PercentFormatter())

    plt.legend(handlelength=0.8, framealpha=0.4, loc='upper left')
    plt.tight_layout()
    plt.savefig('cvar.pdf')
    plt.show()

  # Record results
  new_row = pd.DataFrame({'Strategy': strat_name, 'Prob': [prob],'Mean': [mean_ret], 'STD': [std_ret], 'VaR': [qtl], 'CVaR': [cvar]})
  df_metrics = pd.concat([df_metrics, new_row], ignore_index=True)
  return df_metrics, Rx_t, Ry_t

def strat_plot(df_metrics, show_scaled = True):
  if show_scaled:
    CVaR_scaled = (df_metrics['CVaR'] - np.min(df_metrics['CVaR']))/(np.max(df_metrics['CVaR'])- np.min(df_metrics['CVaR']))
    # VaR_scaled = (df_metrics['VaR'] - np.min(df_metrics['VaR']))/(np.max(df_metrics['VaR'])- np.min(df_metrics['VaR']))
    Mean_scaled = (df_metrics['Mean'] - np.min(df_metrics['Mean']))/(np.max(df_metrics['Mean'])- np.min(df_metrics['Mean']))
    STD_scaled = (df_metrics['STD'] - np.min(df_metrics['STD']))/(np.max(df_metrics['STD'])- np.min(df_metrics['STD']))
    plt.plot(df_metrics['Strategy'], CVaR_scaled, label='CVaR_scaled')
    # plt.plot(df_metrics['Strategy'], VaR_scaled, label='VaR_scaled')
    plt.plot(df_metrics['Strategy'], Mean_scaled, label='Mean_scaled')
    plt.plot(df_metrics['Strategy'], STD_scaled, label='STD_scaled')
  else:
    plt.plot(df_metrics['Strategy'], df_metrics['CVaR'], label='CVaR')
    # plt.plot(df_metrics['Strategy'], df_metrics['VaR'], label='VaR')
    plt.plot(df_metrics['Strategy'], df_metrics['Mean'], label='Mean')
    plt.plot(df_metrics['Strategy'], df_metrics['STD'], label='STD')
  plt.xticks(rotation=45)
  plt.grid(True)
  plt.legend()
  plt.show()

"""### Example: Allocation in proportion to pool's volatility"""

sigma = np.array(params["sigma"])
df_sigma = df_metrics.head(1)

for power in range(3, 10):
  xs_0 = np.power((sigma[1:]),power)/sum(np.power((sigma[1:]),power))*params["x_0"]
  df_sigma, _, _ = strat_test(xs_0, df_sigma, strat_name = f"Sigma {power}")

print(df_sigma)

strat_plot(df_sigma, show_scaled = True)

"""## ================================================================================================================================================================

# STRATEGY

## Stochastic Gradient Descent for CVaR
"""

from copy import deepcopy

""" Initialise the pools """
Rx0 = params["Rx0"]
Ry0 = params["Ry0"]
phi = params["phi"]
T = params["T"]
kappa = params["kappa"]
p = params["p"]
sigma = params["sigma"]
alpha = params["alpha"]
tau = params["zeta"]
batch_size = params['batch_size']


"""
Functions
"""

""" Calculate the cvar at a theta"""
def calc_cvar(theta):
  np.set_printoptions(formatter={'float': lambda x: "{0:0.6f}".format(x)})
  np.random.seed(params["seed"])

  pools = amm( Rx=Rx0 , Ry=Ry0 , phi=phi)
  xs_0 = theta*params['x_0']

  l = pools.swap_and_mint(xs_0)
  end_pools,_,_,_,_,_ = pools.simulate(kappa = kappa , p = p , sigma = sigma , T = T , batch_size = batch_size)

  x_T = np.zeros(batch_size)
  for k in range(batch_size):
      x_T[k] = np.sum(end_pools[k].burn_and_swap(l))

  x_0      = np.sum(xs_0)
  log_ret  = np.log(x_T) - np.log(x_0)
  prob = np.mean(log_ret >= params["zeta"])
  qtl   = np.quantile(-log_ret, alpha)
  cvar  = np.mean(-log_ret[-log_ret>=qtl])

  return cvar,prob

""" Calculate the gradient at each theta """
def calc_grad(theta):
  grad = []
  d_theta = 1e-5
  for axis in range(len(theta)):
    theta_plus = deepcopy(theta)
    theta_plus[axis] += d_theta
    theta_plus /= sum(theta_plus)
    theta_minus = deepcopy(theta)
    theta_minus[axis] -= d_theta
    theta_minus /= sum(theta_minus)

    cvar_plus,_= calc_cvar(theta_plus)
    cvar_minus,_ = calc_cvar(theta_minus)
    grad.append((cvar_plus - cvar_minus)/d_theta/2)

  return np.array(grad)


""" For updating theta at each step of SGD """
def update_theta(theta, grad, learn_rate):
  next_theta = theta - learn_rate * grad
  next_theta = project_onto_simplex(next_theta)

  next_theta[next_theta == 0.] = 1e-5
  next_theta = next_theta/sum(next_theta)

  return next_theta


""" For projecting theta on to K after each update """
def project_onto_simplex(theta):
  sorted_theta = np.sort(theta)[::-1]
  cumsum_sorted_theta = np.cumsum(sorted_theta)
  rho = (cumsum_sorted_theta - 1) / np.arange(1, len(theta)+1)
  k = np.where(sorted_theta - rho > 0)[0][-1]
  theta = np.maximum(theta - rho[k], 0)
  return theta


""" Performing Stochastic Gradient Descent """
def SSGD(theta, learn_rate):
  cvars = []
  probs = []
  for i in range(1,Tee):

    grad = calc_grad(theta[i-1])
    theta[i] = update_theta(theta[i-1], grad, learn_rate = learn_rate)
    cvar,prob = calc_cvar(theta[i])
    cvars.append(cvar)
    probs.append(prob)

    print(f"\n#######################################################\nItetration {i}:")
    print(theta[i])
    print(f"CVaR = {cvar:.4f}")

  return cvars, probs

""" Hyperparameters """
eta = 3
Tee = 30

""" Initialize dataframe to record performance """
df_results = pd.DataFrame(columns=['strat', 'cvar_end', 'theta_end' 'probs', 'cvars', 'theta'])

""" Initialize theta randomly and perform SGD """
theta = np.zeros((Tee, 6))
theta[0,:] = np.random.rand(6)
theta[0,:] = theta[0,:] / np.sum(theta[0, :])

print(theta[0])
print(calc_cvar(theta[0]))
cvars, probs = SSGD(theta, learn_rate = eta)

new_row = pd.DataFrame({'strat':f"Eta: {eta}",'cvar_end': cvars[-1], 'probs': [probs],'theta_end':[theta[-1,:]],'cvars':[cvars],'theta':[theta]})
df_results = pd.concat([df_results, new_row], ignore_index=True)

df_results

"""## Generalization on Different Seeds"""

from copy import deepcopy
import time

""" Learning rate (from Statistical Learning with Conditional Value at Risk) """
Dee = 2**.5  # Diameter of K
n = 500.
b = 5.
Tee = 2
Gee = 1.  # G_alpha
eta = (b * (((Dee ** 2) + 1) ** 0.5 * (n ** 0.5)))/(Gee * ((Tee * (n + 2* Tee)) ** 0.5))  # eta is roughly 1.5


""" Initialise the pools """
Rx0 = params["Rx0"]
Ry0 = params["Ry0"]
phi = params["phi"]
T = params["T"]
kappa = params["kappa"]
p = params["p"]
sigma = params["sigma"]
alpha = params["alpha"]
tau = params["zeta"]
batch_size = params['batch_size']


"""Generate 500 arbitrary seeds and set the minibatch size"""
mini_batch_size = 5
seeds = [seed for seed in range(5)]


""" Generate z from 500 seeds """
list_vt = []
list_directiont = []

for seed in seeds:
  np.random.seed(seed)
  pools = amm( Rx=Rx0 , Ry=Ry0 , phi=phi)
  _,_,_, v_t, _, event_direction_t = pools.simulate( kappa = kappa , p = p , sigma = sigma , T = T , batch_size = batch_size)
  list_vt.append(v_t)
  list_directiont.append(event_direction_t)

"""
Additional Functions
"""

""" Track the CVaR on the main seed"""
def calc_main_seed(theta):

  """ Fix the seed """
  np.random.seed(params["seed"])

  Rx0 = params["Rx0"]
  Ry0 = params["Ry0"]
  phi = params["phi"]
  pools = amm( Rx=Rx0 , Ry=Ry0 , phi=phi)
  xs_0 = theta*params['x_0']

  l = pools.swap_and_mint(xs_0)
  end_pools, Rx_t, Ry_t, v_t, event_type_t, event_direction_t =\
  pools.simulate( kappa = kappa , p = p , sigma = sigma , T = T , batch_size = batch_size)

  x_T = np.zeros(batch_size)
  for k in range(batch_size):
    x_T[k] = np.sum(end_pools[k].burn_and_swap(l))
  x_0 = np.sum(xs_0)
  log_ret = np.log(x_T) - np.log(x_0)

  prob = np.mean(log_ret >= params["zeta"])
  qtl   = np.quantile(-log_ret, params["alpha"])
  cvar  = np.mean(-log_ret[-log_ret>=qtl])

  return cvar, prob


""" Calculate the CVaR and Prob at each theta using pre-generated z's """
def calc_cvar_at_seed(theta, seed):

  if seed != params["seed"]:
    """ Initialise the pools """
    pools = amm( Rx=Rx0 , Ry=Ry0 , phi=phi)
    xs_0 = theta*params['x_0']
    l = pools.swap_and_mint(xs_0)

    """ Swap and mint """
    v_t = list_vt[seed]
    event_direction_t = list_directiont[seed]
    end_pools, _, _ = pools.feed_forward(v_t, event_direction_t)

    """ Burn and swap all coins into x """
    x_T = np.zeros(batch_size)
    for k in range(batch_size):
      x_T[k] = np.sum(end_pools[k].burn_and_swap(l))
    x_0 = np.sum(xs_0)
    log_ret = np.log(x_T) - np.log(x_0)

    # compute condition probability
    zeta  = params["zeta"] # 5%
    prob = np.mean(log_ret >= zeta)

    # compute cvar
    alpha = params["alpha"]
    qtl   = np.quantile(-log_ret, alpha)
    cvar  = np.mean(-log_ret[-log_ret>=qtl])

  else:
    cvar, prob = calc_main_seed(theta)

  return cvar, prob


""" Calculate the gradient at each theta using minibatch """
def MSSGD(theta):
  grad = np.zeros((len(theta), mini_batch_size))
  d_theta = 1e-5

  for batch in range(mini_batch_size):
    seed = np.random.choice(seeds)

    for axis in range(len(theta)):
      theta_plus = deepcopy(theta)
      theta_plus[axis] += d_theta
      theta_plus /= sum(theta_plus)
      theta_minus = deepcopy(theta)
      theta_minus[axis] -= d_theta
      theta_minus /= sum(theta_minus)

      cvar_plus, prob = calc_cvar_at_seed(theta_plus, seed)
      cvar_minus, prob = calc_cvar_at_seed(theta_minus, seed)
      grad[axis, batch] = (cvar_plus - cvar_minus)/d_theta/2

  return np.mean(grad, axis = 1)


""" Perform Minibatch Stochastic Gradient Descent """
def SSGD(theta, learn_rate):
  cvars = []
  probs = []
  for i in range(1,Tee):
    start_time = time.time()

    grad = MSSGD(theta[i-1])
    theta[i] = update_theta(theta[i-1], grad, learn_rate = learn_rate)
    cvar, prob = calc_main_seed(theta[i])
    cvars.append(cvar)
    probs.append(prob)

    print(f"\n#######################################################\nItetration {i}:")
    print(theta[i])

    end_time = time.time()
    total_time = end_time - start_time

    np.set_printoptions(formatter={'float': lambda x: "{0:0.6f}".format(x)})
    print(f"CVaR = {cvar:.6f} | Prob = {prob:.3f} | Time = {total_time}")

    assert sum(theta[i]) - 1. < 1e-5, f"Sum of theta is {sum(theta[i]):.5f}"

    ma_5 = sum(cvars[-5:]) / 5
    if all(abs(cvar - ma_5) < 1e-5 for cvar in cvars[-5:]):
        break

  return cvars, probs, i

""" Simulation """
etas =  [eta]
df_results_2 = pd.DataFrame(columns=['strat', 'iterations', 'theta_end', 'cvar_end', 'probs', 'cvars', 'theta_start', 'theta'])
n_random_start =1

for eta in range(len(etas)):
  for random_start in range(n_random_start):
    print(f"\n#######################################################\n#######################################################\nEta: {etas[eta]}, Start: {random_start+1}")

    theta = np.zeros((Tee, 6))
    theta[0,:] = np.random.rand(6)
    theta[0,:] = theta[0,:] / np.sum(theta[0, :])

    print(theta[0])

    cvars, probs, iter_end = SSGD(theta, learn_rate = etas[eta])

    new_row = pd.DataFrame({'strat':f"Eta: {etas[eta]}, Start {random_start+1}",'iterations':iter_end,'cvar_end': cvars[-1], 'probs': [probs], 'theta_start': [theta[0,:]],'theta_end':[theta[iter_end,:]],'cvars':[cvars],'theta':[theta]})
    df_results_2 = pd.concat([df_results_2, new_row], ignore_index=True)

df_results_2
